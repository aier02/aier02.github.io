<!-- build time:Sun Jan 09 2022 21:41:27 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta name="referrer" content="never"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,minimal-ui"><meta name="renderer" content="webkit"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no,email=no,adress=no"><meta name="theme-color" content="#000000"><meta http-equiv="window-target" content="_top"><title>LSTMs | Amadeus</title><meta name="description" content="毕设任务暂定为video classification，一种实现方式使用到了LSTM神经网络，先做简单的入门准备。 Recurrent Neural NetworksRNN(循环神经网络)的提出是传统的CNN难以应对tmporal context的情况下提出的，他的目的就是针对时许关系，把上一个时间的网络输出联合当前时间的输入作为新的当前时间的输入，以实现利用上个时间的信息。未展开的RNN结构展开"><meta name="keywords" content="blog"><meta property="og:type" content="article"><meta property="og:title" content="LSTMs"><meta property="og:url" content="http://aier02.com/2019/01/11/LSTMs/index.html"><meta property="og:site_name" content="Aier02"><meta property="og:description" content="毕设任务暂定为video classification，一种实现方式使用到了LSTM神经网络，先做简单的入门准备。 Recurrent Neural NetworksRNN(循环神经网络)的提出是传统的CNN难以应对tmporal context的情况下提出的，他的目的就是针对时许关系，把上一个时间的网络输出联合当前时间的输入作为新的当前时间的输入，以实现利用上个时间的信息。未展开的RNN结构展开"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://aier02.com/images/190111/RNN-rolled.png"><meta property="og:image" content="http://aier02.com/images/190111/RNN-unrolled.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-SimpleRNN.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-chain.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM2-notation.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-C-line.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-gate.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-focus-f.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-focus-i.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-focus-C.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-focus-o.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-var-peepholes.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-var-tied.png"><meta property="og:image" content="http://aier02.com/images/190111/LSTM3-var-GRU.png"><meta property="og:updated_time" content="2019-01-11T08:59:06.676Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LSTMs"><meta name="twitter:description" content="毕设任务暂定为video classification，一种实现方式使用到了LSTM神经网络，先做简单的入门准备。 Recurrent Neural NetworksRNN(循环神经网络)的提出是传统的CNN难以应对tmporal context的情况下提出的，他的目的就是针对时许关系，把上一个时间的网络输出联合当前时间的输入作为新的当前时间的输入，以实现利用上个时间的信息。未展开的RNN结构展开"><meta name="twitter:image" content="http://aier02.com/images/190111/RNN-rolled.png"><link rel="canonical" href="http://aier02.com/2019/01/11/LSTMs/index.html"><link rel="alternate" href="/atom.xml" title="Aier02" type="application/atom+xml"><link rel="icon" href="/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet"></head><body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="slimContent"><div class="navbar-header"><div class="profile-block text-center"><a id="avatar" href="https://github.com/aier02" target="_blank"><img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200"></a><h2 id="name" class="hidden-xs hidden-sm">Mileeet</h2><h3 id="title" class="hidden-xs hidden-sm hidden-md">software engineer</h3><small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Guangdong, China</small></div><div class="search" id="search-form-wrap"><form class="search-form sidebar-form"><div class="input-group"><input type="text" class="search-form-input form-control" placeholder="搜索"> <span class="input-group-btn"><button type="submit" class="search-form-submit btn btn-flat" onclick="return!1"><i class="icon icon-search"></i></button></span></div></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech> <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div></div><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button></div><nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation"><ul class="nav navbar-nav main-nav"><li class="menu-item menu-item-home"><a href="/."><i class="icon icon-home-fill"></i> <span class="menu-title">首页</span></a></li><li class="menu-item menu-item-archives"><a href="/archives"><i class="icon icon-archives-fill"></i> <span class="menu-title">归档</span></a></li><li class="menu-item menu-item-categories"><a href="/categories"><i class="icon icon-folder"></i> <span class="menu-title">分类</span></a></li><li class="menu-item menu-item-tags"><a href="/tags"><i class="icon icon-tags"></i> <span class="menu-title">标签</span></a></li><li class="menu-item menu-item-repository"><a href="/repository"><i class="icon icon-project"></i> <span class="menu-title">项目</span></a></li><li class="menu-item menu-item-books"><a href="/books"><i class="icon icon-book-fill"></i> <span class="menu-title">书单</span></a></li><li class="menu-item menu-item-links"><a href="/links"><i class="icon icon-friendship"></i> <span class="menu-title">友链</span></a></li><li class="menu-item menu-item-about"><a href="/about"><i class="icon icon-cup-fill"></i> <span class="menu-title">关于</span></a></li></ul><ul class="social-links"><li><a href="https://github.com/aier02" target="_blank" title="Github" data-toggle="tooltip" data-placement="top"><i class="icon icon-github"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul></nav></div></header><aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><div class="widget"><h3 class="widget-title">公告</h3><div class="widget-body"><div id="board"><div class="content"><p>欢迎交流与分享经验!</p></div></div></div></div><div class="widget"><h3 class="widget-title">分类</h3><div class="widget-body"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Kaggle/">Kaggle</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/algorithms/">algorithms</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/blog/">blog</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs229n/">cs229n</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs231n/">cs231n</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cv/">cv</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/dl/">dl</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/leetcode/">leetcode</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/paper/">paper</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/personal-summary/">personal summary</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/pytorch/">pytorch</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/statistical-learning-method/">statistical learning method</a><span class="category-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签</h3><div class="widget-body"><ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ChexNet/">ChexNet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EDA/">EDA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Github-page/">Github page</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ResNet/">ResNet</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/array/">array</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/backpropagation/">backpropagation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/backtracking/">backtracking</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/basic-knowledge/">basic knowledge</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/">blog</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/chain-rule/">chain rule</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/chest-X-ray/">chest X-ray</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cv/">cv</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/demo/">demo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/experience/">experience</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gradient/">gradient</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hash-table/">hash table</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/image-classification/">image classification</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/introduction/">introduction</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jikecloud/">jikecloud</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/keras/">keras</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linear-classification/">linear classification</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linked-list/">linked list</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/namesilo/">namesilo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/notebook/">notebook</a><span class="tag-list-count">18</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/paper-reading/">paper reading</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/plan/">plan</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch/">pytorch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch-cookbook/">pytorch cookbook</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/regularization/">regularization</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/segmentation/">segmentation</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sensetime/">sensetime</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stack/">stack</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/string/">string</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/two-pointers/">two pointers</a><span class="tag-list-count">1</span></li></ul></div></div><div class="widget"><h3 class="widget-title">标签云</h3><div class="widget-body tagcloud"><a href="/tags/CNN/" style="font-size:13px">CNN</a> <a href="/tags/ChexNet/" style="font-size:13px">ChexNet</a> <a href="/tags/EDA/" style="font-size:13px">EDA</a> <a href="/tags/Github-page/" style="font-size:13px">Github page</a> <a href="/tags/Hexo/" style="font-size:13px">Hexo</a> <a href="/tags/ResNet/" style="font-size:13px">ResNet</a> <a href="/tags/SVM/" style="font-size:13px">SVM</a> <a href="/tags/array/" style="font-size:13px">array</a> <a href="/tags/backpropagation/" style="font-size:13px">backpropagation</a> <a href="/tags/backtracking/" style="font-size:13.25px">backtracking</a> <a href="/tags/basic-knowledge/" style="font-size:13.75px">basic knowledge</a> <a href="/tags/blog/" style="font-size:13.5px">blog</a> <a href="/tags/chain-rule/" style="font-size:13px">chain rule</a> <a href="/tags/chest-X-ray/" style="font-size:13px">chest X-ray</a> <a href="/tags/cv/" style="font-size:13.25px">cv</a> <a href="/tags/demo/" style="font-size:13px">demo</a> <a href="/tags/experience/" style="font-size:13px">experience</a> <a href="/tags/gradient/" style="font-size:13px">gradient</a> <a href="/tags/hash-table/" style="font-size:13px">hash table</a> <a href="/tags/image-classification/" style="font-size:13px">image classification</a> <a href="/tags/introduction/" style="font-size:13px">introduction</a> <a href="/tags/jikecloud/" style="font-size:13px">jikecloud</a> <a href="/tags/keras/" style="font-size:13px">keras</a> <a href="/tags/leetcode/" style="font-size:13.25px">leetcode</a> <a href="/tags/linear-classification/" style="font-size:13px">linear classification</a> <a href="/tags/linked-list/" style="font-size:13.25px">linked list</a> <a href="/tags/namesilo/" style="font-size:13px">namesilo</a> <a href="/tags/notebook/" style="font-size:14px">notebook</a> <a href="/tags/paper-reading/" style="font-size:13.25px">paper reading</a> <a href="/tags/plan/" style="font-size:13px">plan</a> <a href="/tags/pytorch/" style="font-size:13px">pytorch</a> <a href="/tags/pytorch-cookbook/" style="font-size:13px">pytorch cookbook</a> <a href="/tags/regularization/" style="font-size:13.25px">regularization</a> <a href="/tags/segmentation/" style="font-size:13.5px">segmentation</a> <a href="/tags/sensetime/" style="font-size:13.25px">sensetime</a> <a href="/tags/stack/" style="font-size:13px">stack</a> <a href="/tags/string/" style="font-size:13px">string</a> <a href="/tags/two-pointers/" style="font-size:13px">two pointers</a></div></div><div class="widget"><h3 class="widget-title">归档</h3><div class="widget-body"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">2</span></li></ul></div></div><div class="widget"><h3 class="widget-title">最新文章</h3><div class="widget-body"><ul class="recent-post-list list-unstyled no-thumbnail"><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/personal-summary/">personal summary</a></p><p class="item-title"><a href="/2022/01/09/summary_2021_1/" class="title">2021 summary</a></p><p class="item-date"><time datetime="2022-01-09T13:38:55.302Z" itemprop="datePublished">2022-01-09</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/cv/">cv</a></p><p class="item-title"><a href="/2019/01/15/inception/" class="title">inception</a></p><p class="item-date"><time datetime="2019-01-15T08:23:32.427Z" itemprop="datePublished">2019-01-15</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/cv/">cv</a></p><p class="item-title"><a href="/2019/01/12/BoW_in_cv/" class="title">BoW in cv</a></p><p class="item-date"><time datetime="2019-01-12T02:59:03.404Z" itemprop="datePublished">2019-01-12</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/dl/">dl</a></p><p class="item-title"><a href="/2019/01/11/gradient-vanishing-&-exploding-problem/" class="title">gradient vanishing &amp; exploding problem</a></p><p class="item-date"><time datetime="2019-01-11T07:33:27.121Z" itemprop="datePublished">2019-01-11</time></p></div></li><li><div class="item-inner"><p class="item-category"><a class="category-link" href="/categories/cv/">cv</a></p><p class="item-title"><a href="/2019/01/11/LSTMs/" class="title">LSTMs</a></p><p class="item-date"><time datetime="2019-01-11T07:33:13.044Z" itemprop="datePublished">2019-01-11</time></p></div></li></ul></div></div></div></aside><aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar"><div class="slimContent"><nav id="toc" class="article-toc"><h3 class="toc-title">文章目录</h3><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#recurrent-neural-networks"><span class="toc-number">1.</span> <span class="toc-text">Recurrent Neural Networks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lstm-networks"><span class="toc-number">2.</span> <span class="toc-text">LSTM Networks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-core-idea-behind-lstms"><span class="toc-number">3.</span> <span class="toc-text">The Core Idea Behind LSTMs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#step-by-step-lstm-walk-through"><span class="toc-number">4.</span> <span class="toc-text">Step-by-Step LSTM Walk Through</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#variants-on-long-short-term-memory"><span class="toc-number">5.</span> <span class="toc-text">Variants on Long Short Term Memory</span></a></li></ol></nav></div></aside><main class="main" role="main"><div class="content"><article id="post-LSTMs" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting"><div class="article-header"><h1 class="article-title" itemprop="name">LSTMs</h1><div class="article-meta"><span class="article-date"><i class="icon icon-calendar-check"></i> <a href="/2019/01/11/LSTMs/" class="article-date"><time datetime="2019-01-11T07:33:13.044Z" itemprop="datePublished">2019-01-11</time></a></span> <span class="article-category"><i class="icon icon-folder"></i> <a class="article-category-link" href="/categories/cv/">cv</a></span> <span class="article-tag"><i class="icon icon-tags"></i> <a class="article-tag-link" href="/tags/blog/">blog</a></span> <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2019/01/11/LSTMs/#comments" class="article-comment-link">评论</a></span></div></div><div class="article-entry markdown-body" itemprop="articleBody"><p>毕设任务暂定为video classification，一种实现方式使用到了LSTM神经网络，先做简单的入门准备。</p><h3 id="recurrent-neural-networks"><a class="markdownIt-Anchor" href="#recurrent-neural-networks"></a> Recurrent Neural Networks</h3><p>RNN(循环神经网络)的提出是传统的CNN难以应对tmporal context的情况下提出的，他的目的就是针对时许关系，把上一个时间的网络输出联合当前时间的输入作为新的当前时间的输入，以实现利用上个时间的信息。</p><p>未展开的RNN结构</p><p><img src="/images/190111/RNN-rolled.png" alt="RNN-rolled"></p><p>展开的RNN结构</p><p><img src="/images/190111/RNN-unrolled.png" alt="RNN-unrolled"></p><p>一般RNN的问题在于伴随着gap的变大，网络的输出与之前的较久的输出的关系不断减弱，使得后面的网络无法学习到较早的知识，即存在长时间的依赖问题。</p><h3 id="lstm-networks"><a class="markdownIt-Anchor" href="#lstm-networks"></a> LSTM Networks</h3><p>Long Short Term Memory networks的提出就是针对普通RNN固有的记忆时间短的问题，是一种特殊的RNN，善于解决长时间依赖问题，LSTM默认的行为时记住长时间的信息，所有的RNN都具有重复nn的链式结构</p><ul><li>标准RNN的链式结构</li></ul><p><img src="/images/190111/LSTM3-SimpleRNN.png" alt="LSTM3-SimpleRNN"></p><ul><li>LSTM的链式结构</li></ul><p><img src="/images/190111/LSTM3-chain.png" alt="LSTM3-chain"></p><p>上图各种标示的意义</p><p><img src="/images/190111/LSTM2-notation.png" alt="LSTM2-notation"></p><p>黄色的矩形表示用于学习的神经网络，粉色的原点表示逐点的运算，横箭头表示向量的操作，两条线的合箭头表示串联，分箭头表示复制了该向量，并分别用于不同的部分。</p><h3 id="the-core-idea-behind-lstms"><a class="markdownIt-Anchor" href="#the-core-idea-behind-lstms"></a> The Core Idea Behind LSTMs</h3><p>LSTM中的关键时cell state，下图中顶部的水平线即为cell state的传送路径，用于信息传送,他能直接贯通整个LSTM；</p><p><img src="/images/190111/LSTM3-C-line.png" alt="LSTM3-C-line"></p><p>LSTM中用gate实现对cell state的信息移除或者添加，gate是一条有选择性的信息通路，它由sigmoid神经网络层和一个逐点乘法运算组成。通过sigmoid决定要通过的程度，与cell state相乘得到想要控制通过的cell state部分</p><p><img src="/images/190111/LSTM3-gate.png" alt="LSTM3-gate"></p><p>s型曲线的输出为[0,1]，0表示全部信息都不通过，相反1为全部信息通过。一个LSTM中有3个这样的gate，用于控制和保护cell state.</p><h3 id="step-by-step-lstm-walk-through"><a class="markdownIt-Anchor" href="#step-by-step-lstm-walk-through"></a> Step-by-Step LSTM Walk Through</h3><ol><li>LSTM中的第一步是决定哪些信息需要从cell state中移除，利用sigmoid layer实现这一操作，即通过‘forget gate layer’，控制信息是否通过，利用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">h_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:.69444em"></span><span class="strut bottom" style="height:.902771em;vertical-align:-.208331em"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:.15em;margin-right:.05em;margin-left:0"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span>​</span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:.43056em"></span><span class="strut bottom" style="height:.58056em;vertical-align:-.15em"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:.15em;margin-right:.05em;margin-left:0"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span>​</span></span></span></span></span></span>的信息输出0到1，0表示全部‘忘记’，1表示‘记住’上一次全部的cell state.</li></ol><p><img src="/images/190111/LSTM3-focus-f.png" alt="LSTM3-focus-f"></p><p>2.第二步是要决定哪些新的信息需要保存在cell state中，包括两个部分：</p><ul><li>input gate layer：一个sigmoid layer，决定了需要更新哪些值。</li><li>Tanh layer:创建新的候选cell state向量</li></ul><p><img src="/images/190111/LSTM3-focus-i.png" alt="LSTM3-focus-i"></p><p>3.第三步综合之前两步决定要遗忘的信息和要更新的信息，更新本次的cell state，新的cell state由两部分组成：</p><ul><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo>∗</mo><msub><mi>c</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">f_t*c_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:.69444em"></span><span class="strut bottom" style="height:.902771em;vertical-align:-.208331em"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:.10764em">f</span><span class="vlist"><span style="top:.15em;margin-right:.05em;margin-left:-.10764em"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span>​</span></span></span><span class="mbin">∗</span><span class="mord"><span class="mord mathit">c</span><span class="vlist"><span style="top:.15em;margin-right:.05em;margin-left:0"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span>​</span></span></span></span></span></span>上一次的cell state 乘以遗忘系数得到目前需要的旧cell state 的信息程度。</li><li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>i</mi><mi>t</mi></msub><mo>∗</mo><mover accent="true"><mrow><msub><mi>c</mi><mi>t</mi></msub></mrow><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">i_t*\overline{c_t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:.65952em"></span><span class="strut bottom" style="height:.80952em;vertical-align:-.15em"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">i</span><span class="vlist"><span style="top:.15em;margin-right:.05em;margin-left:0"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span>​</span></span></span><span class="mbin">∗</span><span class="overline mord"><span class="vlist"><span style="top:0"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em">​</span></span><span class="mord textstyle cramped"><span class="mord"><span class="mord mathit">c</span><span class="vlist"><span style="top:.15em;margin-right:.05em;margin-left:0"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">t</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0">​</span></span>​</span></span></span></span></span><span style="top:-.5505599999999999em"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em">​</span></span><span class="reset-textstyle textstyle uncramped overline-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em">​</span></span>​</span></span></span></span></span></span>要更新的信息值对应的index乘以候选的cell state得到本次要更新后的候选cell state</li></ul><p><img src="/images/190111/LSTM3-focus-C.png" alt="LSTM3-focus-C"></p><p>4.最后决定输出，先通过一个sigmoid layer决定cell state哪些部分需要输出(该操作和第三步的决定cell state哪些部分需要更新的操作一致)，同时将之前3步算出来的cell state通过tanh layer(压缩输出到[-1,1])，然后tanh layer 得到的值和sigmoid layer 得到的值进行相乘，得到最后要输出的部分。</p><p><img src="/images/190111/LSTM3-focus-o.png" alt="LSTM3-focus-o"></p><h3 id="variants-on-long-short-term-memory"><a class="markdownIt-Anchor" href="#variants-on-long-short-term-memory"></a> Variants on Long Short Term Memory</h3><p>上述为正常的LSTM结构，但是在不同情况下可能存在不同LSTM，下面分别描述不同的变体。</p><p>1.gate layer也关注cell state,即cell state也作为所有gate的输入，术语上说是给gate layer添加一个peephole</p><p><img src="/images/190111/LSTM3-var-peepholes.png" alt="LSTM3-var-peepholes"></p><p>2.直接使用成对的forget gate 和 input gate，同时决定遗忘的部分和更新的部分；而不是分别去决定哪些需要忘记和哪些需要添加。</p><p><img src="/images/190111/LSTM3-var-tied.png" alt="LSTM3-var-tied"></p><ol start="3"><li>比较特别的变体是Gated Recurrent Unit，将forget gate和input gate合并为了一个update gate,同时合并了cell state 和hidden state</li></ol><p><img src="/images/190111/LSTM3-var-GRU.png" alt="LSTM3-var-GRU"></p></div><div class="article-footer"><blockquote class="mt-2x"><ul class="post-copyright list-unstyled"><li class="post-copyright-link hidden-xs"><strong>本文链接：</strong> <a href="http://aier02.com/2019/01/11/LSTMs/" title="LSTMs" target="_blank" rel="external">http://aier02.com/2019/01/11/LSTMs/</a></li></ul></blockquote><div class="panel panel-default panel-badger"><div class="panel-body"><figure class="media"><div class="media-left"><a href="https://github.com/aier02" target="_blank" class="img-burn thumb-sm visible-lg"><img src="/images/avatar.jpg" class="img-rounded w-full" alt=""></a></div><div class="media-body"><h3 class="media-heading"><a href="https://github.com/aier02" target="_blank"><span class="text-dark">Mileeet</span><small class="ml-1x">software engineer</small></a></h3><div>个人简介。</div></div></figure></div></div></div></article><section id="comments"><div id="vcomments"></div></section></div><nav class="bar bar-footer clearfix" data-stick-bottom><div class="bar-inner"><ul class="pager pull-left"><li class="prev"><a href="/2019/01/11/gradient-vanishing-&-exploding-problem/" title="gradient vanishing &amp; exploding problem"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a></li><li class="next"><a href="/2019/01/10/epoch & iteration/" title="epoch &amp; iteration"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a></li><li class="toggle-toc"><a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button"><span>[&nbsp;</span><span>文章目录</span> <i class="text-collapsed icon icon-anchor"></i> <i class="text-in icon icon-close"></i> <span>]</span></a></li></ul><div class="bar-right"><div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div></div></div></nav></main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter"><ul class="social-links"><li><a href="https://github.com/aier02" target="_blank" title="Github" data-toggle="tooltip" data-placement="top"><i class="icon icon-github"></i></a></li><li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li></ul><div class="copyright"><div class="publishby">Theme by <a href="https://github.com/cofess" target="_blank">cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.</div></div></footer><script src="https://cdn.bootcss.com/jquery/1.12.4/jquery.min.js"></script><script>window.jQuery||document.write('<script src="js/jquery.min.js"><\/script>')</script><script src="/js/plugin.min.js"></script><script src="/js/application.js"></script><script>!function(T){var N={TRANSLATION:{POSTS:"文章",PAGES:"页面",CATEGORIES:"分类",TAGS:"标签",UNTITLED:"(未命名)"},ROOT_URL:"/",CONTENT_URL:"/content.json"};T.INSIGHT_CONFIG=N}(window)</script><script src="/js/insight.js"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/npm/valine"></script><script type="text/javascript">var GUEST=["nick","mail","link"],meta="nick,mail,link";meta=meta.split(",").filter(function(e){return GUEST.indexOf(e)>-1}),new Valine({el:"#vcomments",verify:!1,notify:!1,appId:"EkgjNDuvPLC2P4JUvz9XLze6-gzGzoHsz",appKey:"mKLzHHOFc0SEcUIl3DvykWdG",placeholder:"Just go go",avatar:"mm",meta:meta,pageSize:"10",visitor:!1})</script></body></html><!-- rebuild by neat -->