{"meta":{"title":"Aier02","subtitle":null,"description":null,"author":"易安明","url":"http://aier02.com"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-08-06T10:41:28.220Z","updated":"2018-08-04T16:46:32.021Z","comments":false,"path":"/404.html","permalink":"http://aier02.com//404.html","excerpt":"","text":""},{"title":"关于","date":"2018-08-06T10:42:02.162Z","updated":"2018-08-04T16:46:32.022Z","comments":false,"path":"about/index.html","permalink":"http://aier02.com/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2018-08-05T02:38:10.217Z","updated":"2018-08-04T16:46:32.022Z","comments":false,"path":"books/index.html","permalink":"http://aier02.com/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-08-05T02:38:10.227Z","updated":"2018-08-04T16:46:32.022Z","comments":false,"path":"categories/index.html","permalink":"http://aier02.com/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2018-08-05T02:19:10.292Z","updated":"2018-08-04T16:46:32.023Z","comments":false,"path":"repository/index.html","permalink":"http://aier02.com/repository/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-08-05T02:19:59.559Z","updated":"2018-08-04T16:46:32.023Z","comments":true,"path":"links/index.html","permalink":"http://aier02.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-08-05T02:38:10.236Z","updated":"2018-08-04T16:46:32.023Z","comments":false,"path":"tags/index.html","permalink":"http://aier02.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Linear classification","slug":"linear_classification","date":"2018-10-03T05:31:44.756Z","updated":"2018-10-03T08:07:52.057Z","comments":true,"path":"2018/10/03/linear_classification/","link":"","permalink":"http://aier02.com/2018/10/03/linear_classification/","excerpt":"","text":"Linear classification Multiclass SVM基本形式为y=wx+b，此时的x为列向量，一列为一个样本，w的每一行为一个class的template。loss function:Multiclass Support Vector Machine (SVM) loss,SVM “wants” the correct class for each image to a have a score higher than the incorrect classes by some fixed margin Δ;Δ为超参，需要人为设定，它的存在说明多类svm关注的和普通的svm思想上是一致的，都是关注距离超平面一定范围内的误分类点，也就是间隔边界内的点，所以这里的损失函数和合页损失函数的设计是一样的；故第i张图像的损失函数为$$L_i = \\sum_{j\\neq y_i} \\max(0, s_j - s_{y_i} + \\Delta)$$注意这里的sj表示的是该图像在第j类的得分，而yi表示的是该图像的label，即只要计算其错误分类的所有分数和正确分类的分数的差值之和，当label类的得分没有大于某个非label类得分margin时，两者的差值会被算入loss中。引入regularization$$R(W) = \\sum_k\\sum_l W_{k,l}^2$$完整的multicalss SVM loss:$$L = \\underbrace{ \\frac{1}{N} \\sum_i L_i }\\text{data loss} + \\underbrace{ \\lambda R(W) }\\text{regularization loss} \\\\$$扩展形式为:$$L = \\frac{1}{N} \\sum_i \\sum_{j\\neq y_i} \\left[ \\max(0, f(x_i; W)j - f(x_i; W){y_i} + \\Delta) \\right] + \\lambda \\sum_k\\sum_l W_{k,l}^2$$λ\\lambdaλ为超参，常用cross validation确定，表示模型的一种偏好。L2范数作为正则化项的好处是:The most appealing property is that penalizing large weights tends to improve generalization, because it means that no input dimension can have a very large influence on the scores all by itself,即在wx+b得分一样的情况下，L2范数的模型偏向于选择smaller and diffuse weights，使得没有哪个维度影响很大。setting delta:一般设置为1.0是安全的，在loss function中delta和lambda其实具有相同effect在tradeoff上，所以真正有意义的是对于lambda的控制与二分类的svm比较:$$L_i = C \\max(0, 1 - y_i w^Tx_i) + R(W)$$这里的yi∈{−1,1}y_i \\in \\{ -1,1 \\}y​i​​∈{−1,1} Softmax classifierf(xi;W)=Wxif(x_i; W) = W x_if(x​i​​;W)=Wx​i​​和svm保持一致，但经过softmax层用于指示概率的大小，损失函数由hinge loss变成cross-entropy loss$$L_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right) \\hspace{0.5in} \\text{or equivalently} \\hspace{0.5in} L_i = -f_{y_i} + \\log\\sum_j e^{f_j}$$fj(z)=ezj∑kezkf_j(z) = \\frac{e^{z_j}}{\\sum_k e^{z_k}}f​j​​(z)=​∑​k​​e​z​k​​​​​​e​z​j​​​​​​称为softmax function,这里的z即为wx+b，整个softmax function estimated class probabilities，即unnormalized log probabilities交叉熵:p为true distibution，q为estimated distributionH(p,q)=−∑xp(x)logq(x)H(p,q) = - \\sum_x p(x) \\log q(x)H(p,q)=−​x​∑​​p(x)logq(x)Practical issues: Numeric stability:efyi∑jefj=CefyiC∑jefj=efyi+logC∑jefj+logC\\frac{e^{f_{y_i}}}{\\sum_j e^{f_j}} = \\frac{Ce^{f_{y_i}}}{C\\sum_j e^{f_j}} = \\frac{e^{f_{y_i} + \\log C}}{\\sum_j e^{f_j + \\log C}}​∑​j​​e​f​j​​​​​​e​f​y​i​​​​​​​​=​C∑​j​​e​f​j​​​​​​Ce​f​y​i​​​​​​​​=​∑​j​​e​f​j​​+logC​​​​e​f​y​i​​​​+logC​​​​常用的设置方法是logC=−maxjfj\\log C = -\\max_j f_jlogC=−max​j​​f​j​​The Softmax classifier gets its name from the softmax function, which is used to squash the raw class scores into normalized positive values that sum to one, so that the cross-entropy loss can be applied. SVM vs. Softmax主要区别在有loss function:两者的分数向量f都是一样的，不同的在于对f的解释，svm认为f是对应种类的得分，hinge loss鼓励正确的class得分比所有错误的class score都高出一个margin；而softmax认为f是在没有标准化之前表示的是属于某个种类的log概率，并且cross entropy鼓励正确的正确分类的概率大(-log§变小)Hence, the probabilities computed by the Softmax classifier are better thought of as confidences where, similar to the SVM Further ReadingDeep Learning using Linear Support Vector Machines from Charlie Tang 2013 presents some results claiming that the L2SVM outperforms Softmax.","categories":[{"name":"cs231n","slug":"cs231n","permalink":"http://aier02.com/categories/cs231n/"}],"tags":[{"name":"notebook","slug":"notebook","permalink":"http://aier02.com/tags/notebook/"},{"name":"linear classification","slug":"linear-classification","permalink":"http://aier02.com/tags/linear-classification/"},{"name":"SVM","slug":"SVM","permalink":"http://aier02.com/tags/SVM/"}]},{"title":"pytorch cookbook U2&U3","slug":"pytorch_cookbook","date":"2018-10-02T08:27:32.398Z","updated":"2018-10-03T08:10:50.375Z","comments":true,"path":"2018/10/02/pytorch_cookbook/","link":"","permalink":"http://aier02.com/2018/10/02/pytorch_cookbook/","excerpt":"","text":"pytorch-cookbook 第二章函数名后带下划线会修改函数本身如y.add_(x)会直接修改ypytorch的tensor和numpy的对象共享内存，两者同时改变;对于tensor不支持的操作，可以先转为numpy进行操作在转为tensor（tensor支持gpu）1234a=t.ones(5)b = a.numpy() # Tensor -&gt; Numpya = np.ones(5)b = t.from_numpy(a) # Numpy-&gt;Tensortensor[idx]得到的为0-dim的tensor，scalar.item()获取tensor的单个元素对象t.Tensor(5,3)创建5行3列的tensor，t.tensor([3,4])创建包含3，4两个元素的tensort.tensor()会进行数据拷贝，新的tensor和旧的不共享内存，而torch.from_numpy（）或者tensor.detach()则相反使用gpu123device = t.device(&quot;cuda:0&quot; if t.cuda.is_available() else &quot;cpu&quot;)x = x.to(device)y = y.to(device)autograd: 自动微分;要想使得Tensor使用autograd功能，只需要设置tensor.requries_grad=True.如：x = t.ones(2, 2, requires_grad=True)注意：grad在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以反向传播之前需把梯度清零。# 以下划线结束的函数是inplace操作，会修改自身的值，就像add__1x.grad.data.zero_()一起求导的过程示例123456x=t.ones(2,2,requires_grad=True)#生成tensory=x.sum()#定义表达式y.grad_fn#查看求导函数y.backward()#back propagationx.grad#查看y对x的导数x.grad.data_zero_()#清空导数缓存空间nerual network的定义主要是对torch.nn模块的使用,定义网络时，需要继承nn.Module，并实现它的forward方法，把网络中具有可学习参数的层放在构造函数__init__中。如果某一层(如ReLU)不具有可学习的参数，则既可以放在构造函数中，也可以不放，但建议不放在其中，而在forward中使用nn.functional代替,forwar的输入和输出都是tensor,input = t.randn(1, 1, 32, 32),需要注意的是，torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用 input.unsqueeze(0)将batch_size设为１,size形式为nSamples x nChannels x height x weight123456789101112131415161718192021222324252627282930import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): # nn.Module子类的函数必须在构造函数中执行父类的构造函数 # 下式等价于nn.Module.__init__(self) super(Net, self).__init__() # 卷积层 &apos;1&apos;表示输入图片为单通道, &apos;6&apos;表示输出通道数，&apos;5&apos;表示卷积核为5*5 self.conv1 = nn.Conv2d(1, 6, 5) # 卷积层 self.conv2 = nn.Conv2d(6, 16, 5) # 仿射层/全连接层，y = Wx + b self.fc1 = nn.Linear(16*5*5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # 卷积 -&gt; 激活 -&gt; 池化 x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), 2) # reshape，‘-1’表示自适应 x = x.view(x.size()[0], -1) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return xnet = Net()print(net)conv layer主要特征是局部连接和权重共享局部连接：每个神经元仅与输入神经元的一块区域连接，这块局部区域称作感受野（receptive field）。在图像卷积操作中，即神经元在空间维度（spatial dimension，即上图示例H和W所在的平面）是局部连接，但在深度上是全部连接。对于二维图像本身而言，也是局部像素关联较强。这种局部连接保证了学习后的过滤器能够对于局部的输入特征有最强的响应。局部连接的思想，也是受启发于生物学里面的视觉系统结构，视觉皮层的神经元就是局部接受信息的。*权重共享：计算同一个深度切片的神经元时采用的滤波器是共享的。例上图中计算o[:,:,0]的每个每个神经元的滤波器均相同，都为W0，这样可以很大程度上减少参数。共享权重在一定程度上讲是有意义的，例如图片的底层边缘特征与特征在图中的具体位置无关。但是在一些场景中是无意的，比如输入的图片是人脸，眼睛和头发位于不同的位置，希望在不同的位置学到不同的特征 。请注意权重只是对于同一深度切片的神经元是共享的，在卷积层，通常采用多组卷积核提取不同特征，即对应不同深度切片的特征，不同深度切片的神经元权重是不共享。另外，偏重对同一深度切片的所有神经元都是共享的。池化是非线性下采样的一种形式，主要作用是通过减少网络的参数来减小计算量，并且能够在一定程度上控制过拟合。网络的可学习参数通过net.parameters()返回,net.named_parameters可同时返回可学习的参数及名称。nn.MSELoss()实现均方误差，nn.CrossEntropyLoss()实现交叉熵损失优化器更新参数1234567891011121314151617 import torch.optim as optim #新建一个优化器，指定要调整的参数和学习率optimizer = optim.SGD(net.parameters(), lr = 0.01) # 在训练过程中 # 先梯度清零(与net.zero_grad()效果一样)optimizer.zero_grad() # 计算损失output = net(input)loss = criterion(output, target) #反向传播loss.backward() #更新参数optimizer.step()数据加载和预处理：使用torchvision示例：下面我们来尝试实现对CIFAR-10数据集的分类，步骤如下:使用torchvision加载并预处理CIFAR-10数据集,得到dataset和dataloader定义网络,继承nn.Module,init中写入可学习的参数函数，forward定义好前向传播的过程定义损失函数和优化器，criterion和optimizer训练网络并更新网络参数，在每个ephco中加载数据，传入net，算loss，loss.backward，optimizer.step测试网络定义对数据的预处理:将两种转化合并一起；ToTensor()将shape为(H, W, C)的nump.ndarray或img转为shape为(C, H, W)的tensor，其将每一个数值归一化到[0,1]，其归一化方法比较简单，直接除以255即可，加入normalize则其作用就是先将输入归一化到(0,1)，再使用公式”(x-mean)/std”，将每个元素分布到(-1,1),函数normalize（std,mean）1234transform = transforms.Compose([ transforms.ToTensor(), # 转为Tensor transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化 ])Dataset对象是一个数据集，可以按下标访问，返回形如(data, label)的数据。Dataloader是一个可迭代的对象，它将dataset返回的每一条数据拼接成一个batch，并提供多线程加速优化和数据打乱等操作。当程序对dataset的所有数据遍历完一遍之后，相应的对Dataloader也完成了一次迭代，先定义好dataset，然后定义dataloader对指定的dataset进行操作123456789101112 # 训练集trainset = tv.datasets.CIFAR10( root=&apos;/home/cy/tmp/data/&apos;, train=True, download=True, transform=transform)trainloader = t.utils.data.DataLoader( trainset, batch_size=4, shuffle=True, num_workers=2)进行normaliza的必要性：每个样本图像减去数据集图像的均值后除以方差，保证了所有图像的分布相似，使得model训练的时候更快的收敛.训练网络的示例12345678910111213141516171819202122232425262728t.set_num_threads(8)for epoch in range(2): running_loss = 0.0 for i, data in enumerate(trainloader, 0): # 输入数据 inputs, labels = data # 梯度清零 optimizer.zero_grad() # forward + backward outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() # 更新参数 optimizer.step() # 打印log信息 # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0] running_loss += loss.item() if i % 2000 == 1999: # 每2000个batch打印一下训练状态 print(&apos;[%d, %5d] loss: %.3f&apos; \\ % (epoch+1, i+1, running_loss / 2000)) running_loss = 0.0print(&apos;Finished Training&apos;) 第三章表3-1: 常见新建tensor的方法函数功能Tensor(*sizes)基础构造函数tensor(data,)类似np.array的构造函数ones(*sizes)全1Tensorzeros(*sizes)全0Tensoreye(*sizes)对角线为1，其他为0arange(s,e,step从s到e，步长为steplinspace(s,e,steps)从s到e，均匀切分成steps份rand/randn(*sizes)均匀/标准分布normal(mean,std)/uniform(from,to)正态分布/均匀分布randperm(m)随机排列除了tensor.size()，还可以利用tensor.shape直接查看tensor的形状，tensor.shape等价于tensor.size()tensor = t.Tensor(1,2)创建了一个size为【1，2】的张量vector = t.tensor([1, 2])创建了一个值为（1，2）的向量，size为2scalar = t.tensor(3.14159) 创建了一个值为3.14159的标量，size为【】,区别于size【0】，empty_tensor = t.tensor([])，size存在即为tensor","categories":[{"name":"pytorch","slug":"pytorch","permalink":"http://aier02.com/categories/pytorch/"}],"tags":[{"name":"basic knowledge","slug":"basic-knowledge","permalink":"http://aier02.com/tags/basic-knowledge/"},{"name":"pytorch_cookbook","slug":"pytorch-cookbook","permalink":"http://aier02.com/tags/pytorch-cookbook/"}]},{"title":"first time in Kaggle-summary","slug":"rsna_summary","date":"2018-10-01T16:08:39.573Z","updated":"2018-10-03T08:11:31.492Z","comments":true,"path":"2018/10/02/rsna_summary/","link":"","permalink":"http://aier02.com/2018/10/02/rsna_summary/","excerpt":"","text":"项目存在的问题和解决方案 RSNA 如何开始比赛完全是新手，很早以前就有学长介绍过kaggle，最近看完了cs231n，然后打算试试手，但是一开始并不知道应该做什么，于是就上知乎直接搜了如何打kaggle比赛，找到的很多的都是ml的，但是个人更喜欢cv，添加了关键词后，找到了一篇和我类似经历的blog，知道了kaggle比赛到底是什么，他的每个板块表示的是什么，常用的步骤是什么，有什么需要注意的（这个时候开始意识到我没有gpu，这点必定是后期的瓶颈） 选择平台没有gpu怎么办，没有资源只能去租用云平台跑model，开头抱有侥幸心理，有没有什么免费的平台呢，一开始找到的是google 的colab，听说是免费的，然后我就直接尝试使用，跑了一下mnist的基本模型发现经常自动断开连接，而且他给的免费的硬盘空间只有15g，当时我首先打算打的比赛其实是有关air ship的detection比赛。果然天底下没有免费的午餐，只能另找平台，后来在知乎上看到不少人推荐极客云，他自动帮你搭建好了深度学习的环境，（其实这是个坑，创建的dl环境是不能直接操作整个系统的，任何系统的指令都无法操作，这使得我后来无法进行端口的查询，visdom启动的时候总是提示端口被占用），运行的速度和价钱的确很吸引人 EDA什么是lung opacities，什么是pneumonia，他们两者有什么关系么？由于缺乏领域知识，得益于知乎，我直接奔向了discussion和kernel，果然找到了一篇名为what r lung opacities的kernel，这篇文章由一个具备radiologist领域知识的kaggler提供，他直接介绍了怎么看chest x-ray，黑色的为air，白色的为bone，grey为tissue或者fluid，这个kernel对于我整个项目影响最大，他补充了我xray的领域知识。做eda主要是看各个文件中的数量、样本中是否存在重复，是否有缺失，class_label.csv文件中有多少中不同的class，各自的数量如何，他与train数据集是否一一对应，open（）函数，创建一个reader，next跳过header之后就循环读取reader实现按行读取数据；也可用pd.read_csv实现，value_counts()统计重复的次数，groupby（keyword）可以根据keyword分组；主要用到了matplotlib.pyplot，numpy，pandas，pydicom，glob进行数据可视化 detection？还是segmentation？诚然我一开始看到官方的比赛介绍的时候，我主观上是认为要根据dicom图像提供的病人的个人信息以及图像中的信息进行classification，根据我个人对于部分pneumonia的xray的观察，以及提供的数据集中的bboxes的信息和之前提到的那篇kernel的引导，本次比赛更多的是做能指示pneumonia的lung opacities，而且明显是难以完全sgment出来的（opacities有一种是模糊了心脏和lung的边界。于是决定做detection 数据准备前期所做的数据准备，我的想法是直接把pneumonia的bbox的x,y,w,h装入内存，很明显这中做法有一定的风险，遇到内存不足恐怕直接爆了，后期我选择了使用npy文件先预先读取train_lable的信息，然后每次使用的时候再进行读取，这样的做法个人认为可以避免每次训练的时候进行pydicom数据的转换，也能减少内存的使用，后果用了更多的磁盘空间，而且每次读取npy文件都是存在时间成本的。而且有个严重的问题，就是后期如何做数据增强，是对image进行操作，pydicom.dcmread()和cv2.imread读都是hwc，而且是BGR上的0-255为了使后期进行读取方便，我把使用sitk.ReadImage（dcm）将所有的dcm图像转为png格式，sitk.GetArrayFromImage返回的是（hwc），同时存储患有肺炎的图像的numpy数组和bbox的位置信息（ymin,xmin,ymax,xmax），以npy文件的格式保存，实际上在这次操作中图片都是单通道的，而且都是1024*1024的。然后通过对patientid进行岁进shuffle，创建train和valdation，大概9:1 数据增强经过eda后，lung opacities，no lung opacities/not normal,normal,比例是1:1:1，把lung opacities作为positive，则dataset中存在样例不平衡，考虑进行图像的增强，旋转，平移，亮度改变之类的，由于是x-ray图像，考虑进行图像的仿射变换，但是旋转会涉及bbox的改变，因为之前在数字图像课程实验中学过仿射变换（旋转，缩放，平移）然后就直接实现了rotate_img_bbox(img, bboxes, degree=-45, scale=1.)，mat = cv2.getRotationMatrix2D(center,angle=degree,scale=scale) #affine matrix，仿射矩阵为（2，3）的矩阵，以水平进行划分，前（2，2）子矩阵为线性变换矩阵，（2，1）子矩阵为平移矩阵，用标量的形式来看就是ax+b；T=M【x,y,1】,对原来的bbox的四条边的四个中点进行相同的矩阵变化，然后合并为一个矩阵，表示一个仿射后的矩阵，矩形边框（Bounding Rectangle）是说，用一个最小的矩形，把找到的形状包起来。还有一个带旋转的矩形，面积会更小，即使用rx, ry, rw, rh = cv2.boundingRect(concat)得到摆正后的经过仿射变换的新的bbox，整个图像的变换out_image = cv2.warpAffine(img,mat,(width,height))做各种变换的时候由于数据集较大，而且操作多，经常出现等待时间较长的情况，缺乏可视化，不能确定是完成了操作还是仍然在等待，后来在循环中使用了tqdm进行进度条的显示，可视化了进程的进度。 准备dataset创建类generator(keras.utils.Sequence)，实现的函数分别有内置init()，初始化文件夹路径，文件名，bboxing box，batch_size=32,image_size=256(原图为1024)，shuffle，augment，predict为三者为真还是假内置len（），返回filenames中数据量的大小内置getitem（），以batchz_size为数据单位，根据index确定数据的位置，当predict为真时，返回对应文件名的图像和文件名；否则，返回对应文件名的img图像和msk，注意msks即为bboxes的列表内置load（），通过filename确定patientid，然后读取npy文件获取img_array和bboxes列表（每一项为对应图片的bbox的ymin,xmin,ymax,xmax），创建和img等大小的全0msk，根据npy中的‘bboxes’项将对应的标注框区域设置为1；然后resize图片，特别注意由于训练的时候进行的是batch_train,所以对于img和msk都必须添加一个dimension，作为训练的维度内置loadpredict（），基本操作和load函数一致，不同在与该函数不用获取bboxes信息 搭建神经网络create_downsample(channels, inputs)下采样函数，channels指示filter的大小，inputs指示images，依次使用的是keras.layers.BN(momentum=0.9)-&gt;leakyrelu-&gt;conv2d(padding=same)-&gt;maxpool2d。padding：补0策略，为“valid”, “same” 。“valid”代表只进行有效的卷积，即对边界数据不处理。“same”代表保留边界处的卷积结果，通常会导致输出shape与输入shape相同create_resblock(channels, inputs)resblock函数，一个resblock包含了BN-&gt;LEAKYRELU-&gt;CONV2D-&gt;BN-&gt;LEAKYRELU-&gt;CON2D-&gt;add([x, inputs])(channels用于conv层中filters的数目，即输出的维度，kernel_size指定filter的大小)create_network(input_size, channels, n_blocks=2, depth=4)搭建整个网络，inputs = keras.Input(shape=(input_size, input_size, 1))对输入进行规范化-&gt;conv2d-&gt;创建depth层结构，每个结构中包括了一个downsample和n_block个resblock-&gt;ouput layer依次为BN-&gt;LEAKYRELU-&gt;CONV2D-&gt;UpSampling2D(2**depth)(x)-&gt;将input和output包装为一个model即model = keras.Model(inputs=inputs, outputs=outputs) Resnet背景:随着网络的加深，出现了训练集准确率下降的现象，排除overfitting，针对该问题提出了resnet，以允许实现尽可能地加深网络resnet中提出了两种mapping，identity mapping 和 residual mapping，输出为y=F(x)+x,显然x为前者，F(x)为后者；理论上，对于“随着网络加深，准确率下降”的问题，Resnet提供了两种选择方式，也就是identity mapping和residual mapping，如果网络已经到达最优，继续加深网络，residual mapping将被push为0，只剩下identity mapping，这样理论上网络一直处于最优状态了，网络的性能也就不会随着深度增加而降低了。即真正学习的是残差，而形式上y保证了不会出现网络加深而经验误差增大的现象在resnet中加入1*1的conv layer就是bottleneck layer，目的是为了降维，降低计算量和参数的数目，最后又升维是为了保持和输入x的dimensions一致 Batch NormalizationBatchNorm就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布的。(IID独立同分布假设，就是假设训练数据和测试数据是满足相同分布的，这是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障在训练过程中，隐层的输入分布老是变来变去，这就是所谓的“Internal Covariate Shift”，Internal指的是深层网络的隐层，是发生在网络内部的事情，而不是covariate shift问题只发生在输入层。然后提出了BatchNorm的基本思想：能不能让每个隐层节点的激活输入分布固定下来呢？这样就避免了“Internal Covariate Shift”问题了。启发式思考：对输入图像进行白化（Whiten）操作的话——所谓白化，就是对输入数据分布变换到0均值，单位方差的正态分布——那么神经网络会较快收敛；BN所做的可以理解为对深层神经网络每个隐层神经元的激活值做简化版本的白化操作简而言之，对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。因为梯度一直都能保持比较大的状态，所以很明显对神经网络的参数调整效率比较高，就是变动大，就是说向损失函数最优值迈动的步子大，也就是说收敛地快。将输入x的分布强制转换到均值为0，方差为1的正态分布。经过BN后，目前大部分Activation的值落入非线性函数的线性区内，其对应的导数远离导数饱和区，这样来加速训练收敛过程。BN为了保证非线性的获得，对变换后的满足均值为0方差为1的x又进行了scale加上shift操作(y=scale*x+shift)，每个神经元增加了两个参数scale和shift参数，这两个参数是通过训练学习到的，意思是通过scale和shift把这个值从标准正态分布左移或者右移一点并长胖一点或者变瘦一点①不仅仅极大提升了训练速度，收敛过程大大加快；②还能增加分类效果，一种解释是这是类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；③另外调参过程也简单多了，对于初始化要求没那么高，而且可以使用大的学习率等 定义loss function定义iou损失函数:iou_loss(y_true, y_pred),这里的label(即y)是mask，即bboxes为1的0-1图像，intersection = tf.reduce_sum(y_true * y_pred)求的共同区域的1的个数，score = (intersection + 1.) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)，注意+1.是为了保证score不为0，公式为inserction/union。reduce_sum返回该矩阵所有元素之和合并损失函数:0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)，binary_crossentropy为对数损失函数 训练参数的设置定义tf.metric算子，即评估指标算子，用于计算accuracymodel.compile(optimizer=‘adam’,loss=iou_bce_loss,metrics=[‘accuracy’, mean_iou])指定优化器，损失函数和accuracy初始化lr=0.01，epoch=25，lr的更新策略:lrx(np.cos(np.pi*x/epochs)+1.)/2,x为动态变化的epochkeras.callbacks.LearningRateScheduler(schedule)该回调函数是用于动态设置学习率，其中schedule函数以epoch号为参数（从0算起的整数），返回一个新学习率（浮点数） 创建train和validation generator指定图片文件夹:folder = ‘./input/stage_1_train_png’训练生成器:train_gen = generator(folder, train_filenames, pneumonia_locations, batch_size=32, image_size=256, shuffle=True, augment=True, predict=False)测试生成器:valid_gen = generator(folder, valid_filenames, pneumonia_locations, batch_size=32, image_size=256, shuffle=False, predict=False) 训练模型history = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate], epochs=25, workers=4, use_multiprocessing=True)用于指定callback内容，即learning rate，训练集，验证集，epoch数量，线程数量 测试模型创建测试数据生成器:test_gen = generator(folder, test_filenames, None, batch_size=25, image_size=256, shuffle=False, predict=True)threshold predicted mask,pred中大于0.5才为maskcomp = pred[:, :, 0] &gt; 0.5apply connected componentscomp = measure.label(comp),measure.label作用是给comp标记连通区域，用于确定不同的bbox，measure.regionprops(comp)获取comp的不同连通区域，返回的region列表，每一个分别为ymin,xmin,ymax,xmax计算置信度proxy for confidence score:conf = np.mean(pred[y:y+height, x:x+width]) 提交结果保存结果到csv文件中:以字典的形式保存到csv文件中save dictionary as csv filesub = pd.DataFrame.from_dict(submission_dict,orient=‘index’)指定索引名称:sub.index.names = [‘patientId’]指定列名:sub.columns = [‘PredictionString’]写入指定目录文件:sub.to_csv(’/input/submission.csv’)","categories":[{"name":"Kaggle","slug":"Kaggle","permalink":"http://aier02.com/categories/Kaggle/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"http://aier02.com/tags/segmentation/"},{"name":"keras","slug":"keras","permalink":"http://aier02.com/tags/keras/"},{"name":"ResNet","slug":"ResNet","permalink":"http://aier02.com/tags/ResNet/"},{"name":"jikecloud","slug":"jikecloud","permalink":"http://aier02.com/tags/jikecloud/"}]},{"title":"python rubbish collection","slug":"python_rubbish_collection","date":"2018-09-28T07:32:02.260Z","updated":"2018-10-03T08:08:16.164Z","comments":true,"path":"2018/09/28/python_rubbish_collection/","link":"","permalink":"http://aier02.com/2018/09/28/python_rubbish_collection/","excerpt":"","text":"python垃圾回收机制 引用计数每个对象维护一个ob_ref字段，每次被别的对象引用的ob_ref加1，若引用失效，则减1，当ob_ref为0则该对象被回收，占用的内存空间被释放。但是该方法不能解决循环引用问题，即两个对象相互引用，当他们的外部引用都失效时，ob_ref仍为1，非零，但是他们实质是要被回收的，而python却不能将其回收 标记清除对活动对象进行标记，将非活动对象进行回收。对象之间通过引用（指针）连在一起，构成一个有向图，对象构成这个有向图的节点，而引用关系构成这个有向图的边。从根对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。根对象就是全局变量、调用栈、寄存器。 分代回收根据对象存活时间的不同对内存进行了划分，时间由短到长分别划分为年轻代，中年代，老年代，新创建的对象都会分配在年轻代，年轻代链表的总数达到上限时，Python垃圾收集机制就会被触发，把那些可以被回收的对象回收掉，而那些不会回收的对象就会被移到中年代去，依此类推，老年代中的对象是存活时间最久的对象，甚至是存活于整个系统的生命周期内。","categories":[{"name":"python","slug":"python","permalink":"http://aier02.com/categories/python/"}],"tags":[{"name":"basic knowledge","slug":"basic-knowledge","permalink":"http://aier02.com/tags/basic-knowledge/"}]},{"title":"faster RCNN","slug":"faster_RCNN","date":"2018-09-18T10:55:07.479Z","updated":"2018-10-03T08:08:10.513Z","comments":true,"path":"2018/09/18/faster_RCNN/","link":"","permalink":"http://aier02.com/2018/09/18/faster_RCNN/","excerpt":"","text":"faster RCNN感受野：在卷积神经网络CNN中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野receptive fieldfatal error: numpy/arrayobject.h: No such file or directory”​这个错误的出现可以如下解决，将setup.py内容加入一条include_dirs=[numpy.get_include()]​就可以了。示例setup.py文件如下：from distutils.core import setupfrom distutils.extension import Extensionfrom Cython.Distutils import build_extimport numpy as npext_modules=[Extension(“test03”,[“test03.pyx”])]setup(name=‘gravity_cy’,cmdclass={‘build_ext’:build_ext},include_dirs = [np.get_include()],ext_modules=ext_modules) 主要问题是要指定numpy的路径过程记录：1）下载faster-rcnn的预训练模型并在demo中进行调试2）运行python misc/convert_caffe_pretrain.py把预训练的vgg16下载并保存到checkpoint中，作为cnn提取器3）","categories":[{"name":"pytorch","slug":"pytorch","permalink":"http://aier02.com/categories/pytorch/"}],"tags":[{"name":"CNN","slug":"CNN","permalink":"http://aier02.com/tags/CNN/"}]},{"title":"analysis kernel demo","slug":"analysis_kernel_demo","date":"2018-09-18T10:55:03.519Z","updated":"2018-10-03T08:20:26.193Z","comments":true,"path":"2018/09/18/analysis_kernel_demo/","link":"","permalink":"http://aier02.com/2018/09/18/analysis_kernel_demo/","excerpt":"","text":"analysis kernel demoBatchNormalization层：该层在每个batch上将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1[]!https://arxiv.org/pdf/1502.03167v3.pdfleakyRelu层：$$LeakyRelu（x） =\\begin{cases}x, &amp; x &gt; 0\\ax, &amp; x &lt;= 0\\end{cases}- pytorch自定义dataset和dataloader - torch.utils.data.Dataset是表示数据集的抽象类。您自定义的数据集应该继承Dataset并重写以下方法： __len__ 使用len(dataset)将返回数据集的大小。 __getitem__ 支持索引，dataset[i]可以获取第i个样本 让我们为我们的人脸标记点数据集创建一个数据集类。我们将在__init__中读取csv，而将在__getitem__存放读取图片的任务。因为所有的图像不是一次性存储在内存中，而是根据需要进行读取，这样可以高效的使用内存。123456789101112131415class CustomDataset(data.Dataset):#需要继承data.Dataset def __init__(self): # TODO # 1. Initialize file path or list of file names. pass def __getitem__(self, index): # TODO # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open). # 2. Preprocess the data (e.g. torchvision.Transform). # 3. Return a data pair (e.g. image and label). #这里需要注意的是，第一步：read one data，是一个data pass def __len__(self): # You should change 0 to the total size of your dataset. return 0将numpy ndarry转为tensor：123456789101112class ToTensor(object): &quot;&quot;&quot;Convert ndarrays in sample to Tensors.&quot;&quot;&quot; def __call__(self, sample): image, landmarks = sample[&apos;image&apos;], sample[&apos;landmarks&apos;] # swap color axis because # numpy image: H x W x C # torch image: C X H X W image = image.transpose((2, 0, 1)) return &#123;&apos;image&apos;: torch.from_numpy(image), &apos;landmarks&apos;: torch.from_numpy(landmarks)&#125;","categories":[{"name":"pytorch","slug":"pytorch","permalink":"http://aier02.com/categories/pytorch/"}],"tags":[{"name":"demo","slug":"demo","permalink":"http://aier02.com/tags/demo/"}]},{"title":"first time in Kaggle-preparation","slug":"rsna_pneumonia_detection","date":"2018-09-06T09:08:00.932Z","updated":"2018-10-03T08:15:40.619Z","comments":true,"path":"2018/09/06/rsna_pneumonia_detection/","link":"","permalink":"http://aier02.com/2018/09/06/rsna_pneumonia_detection/","excerpt":"","text":"Question descriptionIn this competition, you’re challenged to build an algorithm to detect a visual signal for pneumonia in medical images. Specifically, your algorithm needs to automatically locate lung opacities on chest radiographs.(CXR)胸部X线片上肺部阴影的定位以跟踪可能的肺炎病况They see the potential for ML to automate initial detection (imaging screening) of potential pneumonia cases in order to prioritize and expedite their review.But the title “Pneumonia Detection” for the competition is misleading because you actually have to do “Lung Opacities Detection”, and lung opacities are not the same as pneumonia. Lung opacities are vague, fuzzy clouds of white in the darkness of the lungs, which makes detecting them a real challenge.-from a kernal如何确认x照片中的阴影？ Basic informationin CXR:black-air;white-bones;grey-fluid or tissueUsually the lungs are full of air. When someone has pneumonia, the air in the lungs is replaced by other material - fluids, bacteria, immune system cells, etc. That’s why areas of opacities are areas that are grey but should be more black.(找出原来是黑但是变灰了的区域As you can see, lung opacities are not homogenoues and they do not have a clear center or clear boundaries. I don’t think you can properly segment opacities out of the entire picture because there are no clear boundries.-直接找阴影貌似很难，可以先segment lungsin fact, there was only a moderate level of agreement between radiologists about the presence of infiltrates, which are opacities by definition预测任务为病人的dcm图像找到lung opacities,以bbox的形式给出，在submission_file中，一张图片中只能有一条bbox信息，每4个信息项为一个bbox，即(x,y,weight,height) Difficultiesthere is a mass of tissue surrounding the lungs and between the lungs. These areas contain skin, muscles, fat, bones, and also the heart and big blood vessels. That translates into a lot of information on the chest radiograph that is not useful for this competition.阴影有多种，怎样的阴影才和肺炎相关The main difference in the types of opacities between these two patients is the borders and the shape of the opacity, Patient 3 has multiple round and clearly defined opacities. Patient 2 has this poorly defined haziness which obscures the margins of the lungs and heart. This haziness is termed consolidation.Exclude: obvious mass(es), nodule(s), lobar collapse, linear atelectasis要找的阴影是模糊的，难懂的，不明显的In the cases labeled Not Normal/No Lung Opacity, no lung opacity refers to no opacity suspicious for pneumonia. 在数据集中，不正常/没有肺部阴影，是指没有与肺炎相关的阴影，但会有与其他病症相关的阴影，故是不正常。两种肺炎阴影：Ground-Glass Opacities；Consolidations前者We can see that the lungs are “whiter” than they should be, but we can see most of the borders of the lungs and hear后者There are fuzzy areas in the lungs and the borders of the lungs and heart cannot be seen.玻璃粉状的阴影不会影响心脏和肺部的边界，而合并类的阴影会模糊两者的边界预测pneumoni和opacities应该独立预测？lung opacities并不是是pneumonia的充要条件实际上该比赛为Lung Opacities Detectio，而不是Pneumonia Detection exprolatory data analysisstage_1_detailed_class_info里面包括了3种class，共有28989条记录，每条信息为patientid：class，标注了病人id对应的正常、不正常/不是肺炎，肺炎3种情况stage_1_train_labels记录了bbox的位置，同样有28989条记录，每条记录分别是patientid：x,y,width,height,target;x,y表示bbox的左上角的坐标，width是宽度，即x的范围，height是高度，即y的范围，target=0表示没有肺炎，=1表示有肺炎，对应class_info，normal则bbox信息empty，target=0；No Lung Opacity / Not Normal则bbox信息empty，target=0；因此lung opacities in data is associated with pneumonia；lung opacities 则包含了bbox的信息同时target=1注意数据集存在一名病人对应多条记录的情况，并不是有28989名病人，经过eda可知存在25684名病人（patientid）(training data 中有25684张dcm)实际上因为bbox信息表是一条记录只能表示一个bbox，故存在一个病人的cxr中有多个bbox，而class表和label表相一致，所以保持对应关系class存在重复数据训练集中dcm文件不只是image，还有meta information，如sex，age等，是否需要添加此类属性，从而考虑相关的内容进行判断？patientId - A patientId. Each patientId corresponds to a unique image.x_ - the upper-left x coordinate of the bounding box.y_ - the upper-left y coordinate of the bounding box.width_ - the width of the bounding box.height_ - the height of the bounding box.Target_ - the binary Target, indicating whether this sample has evidence of pneumonia.No Lung Opacity / Not Normal and Normal have together the same percent (69.077%) as the percent of missing values for target window in class details information.显然存在正样本偏少的情况，需要做数据增强，过采样？角度偏转？ models ChexNetThe CheXNet algorithm is a 121-layer deep 2D Convolutional Neural Network; a Densenet after Huang &amp; Liu. The Densenet’s multiple residual connections reduce parameters and training time, allowing a deeper, more powerful model. The model accepts a vectorized two-dimensional image of size 224 pixels by 224 pixels.CheXNet is a 121-layer Dense Convolutional Network (DenseNet) (Huang et al., 2016) trained on the ChestX-ray 14 dataset. DenseNets improve flow of information and gradients through the network, making the optimization of very deep networks tractable. We replace the final fully connected layer with one that has a single output, after which we apply a sigmoid nonlinearity. The weights of the network are initialized with weights from a model pretrained on ImageNet (Deng et al., 2009). The network is trained end-to-end using Adam with standard parameters (ß1 = 0.9 and ß2 = 0.999) (Kingma &amp; Ba, 2014). We train the model using minibatches of size 16. We use an initial learning rate of 0.001 that is decayed by a factor of 10 each time the validation loss plateaus after an epoch, and pick the model with the lowest validation loss.","categories":[{"name":"Kaggle","slug":"Kaggle","permalink":"http://aier02.com/categories/Kaggle/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"http://aier02.com/tags/segmentation/"},{"name":"chest X-ray","slug":"chest-X-ray","permalink":"http://aier02.com/tags/chest-X-ray/"},{"name":"ChexNet","slug":"ChexNet","permalink":"http://aier02.com/tags/ChexNet/"},{"name":"EDA","slug":"EDA","permalink":"http://aier02.com/tags/EDA/"}]},{"title":"experience from a Kaggler","slug":"kaggle_expericence","date":"2018-09-05T02:19:10.278Z","updated":"2018-10-03T08:08:35.464Z","comments":true,"path":"2018/09/05/kaggle_expericence/","link":"","permalink":"http://aier02.com/2018/09/05/kaggle_expericence/","excerpt":"","text":"kaggle比赛步骤-经验1.仔细阅读比赛介绍和数据描述；2.查找相似的Kaggle比赛。作为一个接触不久的Kaggler，我已经完成对所有Kaggle比赛基本分析的收集；3.研究相似比赛的解决方案；4.阅读有关论文，以确保不错过该领域的最新进展；5.分析数据，并构建可靠的交叉验证结果；6.数据预处理、特征工程和模型训练。7.结果分析，包括如预测分布、错误分析和困难样本等；8.根据分析来改进模型或设计新模型；9.基于数据分析和结果分析来设计模型以增加多样性或解决困难样本；10.模型集成；11.必要时返回到前面的某个步骤。Q：你觉得，赢得比赛的关键是什么？可靠的验证方式，借鉴其他比赛并阅读相关论文，以及良好的自制力和心理素质。Q：你认为你最具竞争力的比赛技巧或方法是什么？我认为应该是在比赛开始时准备解决方案的文档。我会强迫自己写出一份清单，包括面临的挑战、应该阅读的解决方案和论文、可能的风险、可用的验证方式、可能的数据增强方法以及增加模型多样性的方式。而且，我不断更新这个文档。幸运地，这些文档为我后面在很多比赛中取得不错成绩提供了支持","categories":[{"name":"Kaggle","slug":"Kaggle","permalink":"http://aier02.com/categories/Kaggle/"}],"tags":[{"name":"experience","slug":"experience","permalink":"http://aier02.com/tags/experience/"}]},{"title":"a failed experience in Kaggle","slug":"airbus_ship_detection","date":"2018-09-05T02:18:30.433Z","updated":"2018-10-03T08:08:00.121Z","comments":true,"path":"2018/09/05/airbus_ship_detection/","link":"","permalink":"http://aier02.com/2018/09/05/airbus_ship_detection/","excerpt":"","text":"airbus-ship-detection challenge 问题描述：从卫星图像中找到ships，并用bbox分割出来 难点所在并不是所有图片都有ships在图片中ships的大小不一致图像分割不允许存在部分重叠，但数据集中的ships当两者直接相邻时，存在轻微的overlap，重叠部分将会被作为背景而移除部分带有人工标注的图片中的bbox可能存在边界像素的丢失train-ship-segmentations.csv提供了人工标注的bbox作为训练的数据图片，其中bbox以run-length encoding 表示。数据集很大，需要用到gpu，训练模型可能要几天时间run-length-encoding评价方式为IoU,即人工标注的bbox和预测的bbox的相交部分与两者合并的部分的占比。 EDA(exploratory data analysis)The images (at least many of them) are slices of the same image, not separate frames taken at different times.data leak:The images in test are just shifted versions of images in train. The problem also happens in train, it looks like airbus had bigger images and then the 768x768 are random crops of the bigger images; but it looks they didn’t check whether there were any overlaps.How to find:Run nearest neighbors on all imagesFor each image take N closest neighbors and find where it overlapsCutting all the images 256x256 they can be found easier because they match almost exactly (except for compression artifacts). up to nowdue to data leak,large data set,few computation source and time limit,I decided to pause the competition.","categories":[{"name":"Kaggle","slug":"Kaggle","permalink":"http://aier02.com/categories/Kaggle/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"http://aier02.com/tags/segmentation/"}]},{"title":"Introduction to statistical learning method U1","slug":"statistic_1","date":"2018-08-27T16:58:59.803Z","updated":"2018-10-03T08:31:04.196Z","comments":true,"path":"2018/08/28/statistic_1/","link":"","permalink":"http://aier02.com/2018/08/28/statistic_1/","excerpt":"","text":"李航老师的《统计学习方法》基本已经过一遍了，感觉只是略懂皮毛，现为了加强知识点的认识和部分课后题的实现，有必要进行个人总结。 统计学习 定义statistical learning 是关于计算机基于数据构建构建统计模型并运用模型对数据进行预测和分析的一门学科，是概率论、统计学、信息论、计算理论、最优化理论和计算机科学等学科的交叉学科。 学习对象和目的从数据出发，提取数据的特征，抽象出数据的模型（概率统计模型），并对数据进行预测和分析 实现统计学习方法的一般步骤得到一个有限的训练数据集合确定包含所有可能的模型的假设空间，即学习的模型的集合确定模型选择的准则，即学习的策略实现求解最优模型的算法，即学习的算法通过学习方法选择最优的模型利用最优模型对新的数据进行预测或则分析简而言之：数据-&gt;假设空间-&gt;策略-&gt;算法-&gt;最优模型-&gt;预测分析 监督学习统计学习包括了监督学习，非监督学习，半监督学习和强化学习。 基本概念输入所有可能取值的集合称为输入空间，同理输出所有可能的取值集合称为输出空间，通常output space 远小于 input space；而特征空间则是所有特征向量所在的空间，特征向量用于表示一个输入实例，特征空间的每个维度对应一个特征，输入空间可以和特征空间相同，也可把输入空间映射到空间，模型实质是定义在特征空间上的（对特征向量进行学习）。X表示输入变量，Y表示输出变量，输入变量X中的第i个表示为xi=(xi(1),xi(2),...,xi(n))Tx_i=(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})^Tx​i​​=(x​i​(1)​​,x​i​(2)​​,...,x​i​(n)​​)​T​​N个数据的训练数据集(labled)表示为T={(x1,y1),(x2,y2),...,(xN,yN)}T=\\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\\}T={(x​1​​,y​1​​),(x​2​​,y​2​​),...,(x​N​​,y​N​​)}输入到输出的映射关系由模型进行表示，所有可能的由输入空间（特征空间）到输出空间的映射的集合组成了假设空间，学习的范围局限在假设空间中。 统计学习的三要素 模型统计学习首先考虑是学习什么样的模型，在监督学习中就是要学习的条件概率分布或者决策函数，由所有可能的模型构成的集合组成了假设空间F,通常是一个由参数决定的函数族.决策函数模型的集合表示为$$F={f|Y=f_\\theta(X),\\theta\\in R^n}$$条件概率模型的集合表示为$$F={f|P=P_\\theta(Y|X),\\theta\\in R^n}$$其中θ\\thetaθ取值于n维的欧氏空间，称为参数空间 策略有了假设空间，接着考虑按照什么样的准则学习最优的模型，称为策略。 损失函数和风险函数损失函数度量模型预测的好坏（预测的结果和标记的差距），风险函数度量平均意义下的模型预测的好坏（在具体某次预测可能出错的期望） 损失函数记作L(f(X),Y)&gt;=0,常见类型:0-1损失函数（0-1 loss fuction ）：L(f(X),Y)={1,Y≠f(X)0,Y=f(X)L(f(X),Y) = \\begin{cases} 1, &amp; Y \\neq f(X)\\\\ 0, &amp; Y = f(X) \\end{cases}L(f(X),Y)={​1,​0,​​​Y≠f(X)​Y=f(X)​​平方损失函数(quadratic loss function):L(f(X),Y)=(Y−f(X))2L(f(X),Y) =(Y-f(X))^2L(f(X),Y)=(Y−f(X))​2​​绝对损失函数(absolute loss fuction):L(f(X),Y)=∣(Y−f(X))∣L(f(X),Y) =|(Y-f(X))|L(f(X),Y)=∣(Y−f(X))∣ 经验风险和结构风险模型f(x)关于训练数据集的平均损失称为经验风险：Remp(f)=1N∑i=1NL(yi,f(xi))R_{emp}(f) =\\frac 1N\\sum_{i=1}^NL(y_i,f(x_i))R​emp​​(f)=​N​​1​​​i=1​∑​N​​L(y​i​​,f(x​i​​))结构风险简单而言就是经验风险加入了正则化项，正则化项用于表示模型复杂度，因此结构风险最小化是为了防止过拟合而提出的策略。Rsrm(f)=1N∑i=1NL(yi,f(xi))+λJ(x)R_{srm}(f) =\\frac 1N\\sum_{i=1}^NL(y_i,f(x_i))+\\lambda J(x)R​srm​​(f)=​N​​1​​​i=1​∑​N​​L(y​i​​,f(x​i​​))+λJ(x)其中$\\lambda $&gt;=0,用以权衡经验风险和模型复杂度 算法算法是指学习模型的具体方法，一般而言就是求解模型f中的参数以达到模型的最优化，故很多时候统计学习的算法到最后基本都是最优化问题。 模型评估和模型选择 训练误差训练误差是模型关于训练数据集的平均损失，即前面所说的经验风险；Rexp(f)=1N∑i=1NL(yi,f(xi))R_{exp}(f) =\\frac 1N\\sum_{i=1}^NL(y_i,f(x_i))R​exp​​(f)=​N​​1​​​i=1​∑​N​​L(y​i​​,f(x​i​​)) 测试误差测试误差跟训练误差相似，只是前者是在测试数据集上的平均损失 过拟合和模型选择一味最求模型对于训练数据的预测能力，所求得的模型往往会比真实模型更加复杂，这种现象叫做过拟合（模型参数过多，训练误差很小，但测试误差较大或者泛化能力很差），而模型的选择就是为了避免过拟合并提高模型对于未知数据的预测能力。 正则化模型选择的典型方法是正则化，通过结构风险最小化实现，即在经验风险后加上一个正则化项，一般是模型复杂度的单调递增函数（比如L_2范数）正则化的作用是选择经验风险和模型复杂度同时较小的模型；问题是为什么需要简单的模型？一方面是过拟合的存在使得模型有可能过度关注训练数据集的“个性”，导致模型的泛化能力下降；另一个解释是根据奥卡姆剃刀原理，“如无必要，勿增实体”，即在所有可能选择的模型中，能够很好地解释数据并且十分简单的模型才是最优的（尽管这个要求有点自相矛盾，此时λ\\lambdaλ往往起到折中的作用）；从贝叶斯估计的角度而言，正则化项对应于模型的先验概率，复杂的模型先验概率小，简单的模型先验概率大。 交叉验证基本思想是重复地使用数据，对给定的数据进行划分，然后组合成训练集和测试集，反复进行训练、测试和模型的选择。 简单交叉验证随机把数据集划分为训练集和测试集两部分（训练集更大），改变不同的条件使得在相同的训练集上也能得到不同的模型，然后在测试集进行模型的测试和选择。 S折交叉验证随机地把数据集划分为S个互不相交的子数据集，利用S-1个子数据集作为训练数据集，剩下的一个做为测试集；将这一过程对可能的S中选择重复进行，从得到的S个模型中选择测试误差最小的模型。 留一交叉验证S=N时，用于数据缺乏的情况下，即每次只拿一个数据样本作为测试集，进行N次相同操作，从N个模型中选择最优者（平均测试误差最小）。 泛化能力generalization alibity指由学习方法得到的模型对于未知数据的预测能力，常用测试误差评价学习方法的泛化能力，仅记测试数据集是十分宝贵的，在学习模型的过程中不能使用，要在训练完成后才能用于测试，保证对于学得的模型而言，测试数据是“未知的”。对于泛化能力的分析往往通过研究泛化误差的概率上界进行，常具有以下性质：样本容量增加，泛化上界趋于0；假设空间容量越大，模型就越难学，泛化误差上界就越大。存在定理，对于二类分类问题，当假设空间是有限个函数的集合时F={f1,f2,f3…,fd},对任意一个函数f∈\\in∈F,至少以概率1-δ\\deltaδ,以下不等式成立：R(f)&lt;=R^(f)+ϵ(d,N,δ)R(f)&lt;=\\hat R(f)+\\epsilon (d,N,\\delta)R(f)&lt;=​R​^​​(f)+ϵ(d,N,δ)即泛化误差&lt;=训练误差+N的单调递减函数(右端即为泛化误差的上界)ϵ(d,N,δ)=12N(logd+log1δ)\\epsilon (d,N,\\delta)=\\sqrt {\\frac 1{2N}(logd+log\\frac 1\\delta)}ϵ(d,N,δ)=√​​2N​​1​​(logd+log​δ​​1​​)​​​可见泛化误差上界和训练误差、样本容量均正相关，和模型复杂度d负相关。 生成模型和判别模型 生成模型由生成方法学到的模型称为生成模型，生成方法由数据学习联合概率分布P(X,Y),然后求出条件概率分布P(Y|X)作为预测的模型，即：P(Y∣X)=P(X,Y)P(X)P(Y|X)=\\frac {P(X,Y)}{P(X)}P(Y∣X)=​P(X)​​P(X,Y)​​生成模型表示了给定输入X产生输出Y的生成关系，典型的生成模型由朴素贝叶斯法和隐马尔可夫模型。 判别模型由判别方法学到的模型称为判别模型，判别方法由数据直接学习决策函数f(X)或者条件概率P(Y|X)作为预测的模型。判别模型表示给定输入X应该预测什么样的输出Y。典型的判别模型有k紧邻法，感知机，决策树，逻辑斯谛回归模型，最大熵模型，支持向量机，提升方法，条件随机场等。存在隐变量时不能使用判别方法，但可以用生成方法；判别方法直接面对预测，准确率更高。","categories":[{"name":"statistical learning method","slug":"statistical-learning-method","permalink":"http://aier02.com/categories/statistical-learning-method/"}],"tags":[{"name":"basic knowledge","slug":"basic-knowledge","permalink":"http://aier02.com/tags/basic-knowledge/"},{"name":"introduction","slug":"introduction","permalink":"http://aier02.com/tags/introduction/"}]},{"title":"Build personal blog","slug":"blog_tutorial","date":"2018-08-07T11:24:35.583Z","updated":"2018-10-03T08:30:19.069Z","comments":true,"path":"2018/08/07/blog_tutorial/","link":"","permalink":"http://aier02.com/2018/08/07/blog_tutorial/","excerpt":"","text":"最近在加强ml和cv基础知识的学习，为了加深理解，同时记录自己的学习过程，尝试着写blog；向好友请教后得知建立个人blog的方式，我的选择是Hexo(一种静态博客网页框架)+Github page（免费托管博客项目代码），当然还有租云服务器和自己写后台和前端的方式，前者更加方便和易于上手。 前期准备 安装Git毕竟所有项目代码都是托管到Github上面，必须保证系统中已经安装了git，terminal中输入git不出现commant not found即可 安装Node.js因为Hexo的使用基于Node.js，所以要先安装Node.js和他的包安装器npm,建议到官网下载pkg并选择稳定版本(LTS) Github创建项目在Github上面创建一个名为：yourname.github.io 的空项目，yourname是指你创建的github账户名（github上面每个用户的用户名是唯一的标识），该Repository就是之后你的blog所有代码和文件存放的地方，blog的地址在不添加设置的情况下：https://yourname.github.io 安装Hexo在终端输入npm命令下载静态网页生成器Hexo1npm install -g hexo若出现permiss denied等情况，则加入sudo1sudo npm install -g hexo 创建Hexo文件夹在本地文件系统中创建Hexo文件夹，cd进入该文件夹，然后进行初始化1Hexo init没有错误，则以后所有操作都必须在该文件目录下进行，特别注意文件夹Hexo/node_models,所有通过npm install XXX --save操作下载的依赖都会存放在该文件夹中，易于包的管理(–save参数的意义就是存放在node_models)顺利完成上述步骤后可以登陆https://yourname.github.io 查看效果 绑定个人域名Ps:不想花钱的同学可以跳过 购买国外个人域名对于没有个人域名的同学来说，国内备案实在是太漫长了(我前段时间就在腾讯云备案过一次，周期太长==)，直接购买国外的域名方便而且预算基本一样，推荐namesilo，60一年，后缀多选择而且有免费的private protection；注册的时候我写的假的信息(除了邮箱）；一开始先检索你想注册的域名，然后在根据英文指导取购买就ok了(默认设置),网站支持alipay，非常方便了。 更改DNS统一使用一个dns的话对于以后多域名管会更加方便，推荐使用国内的厂商dnspod，登陆后添加你更注册的域名进行管理，主要添加连个主机记录，分别是@和www,譬如我的设置为图中A记录的记录值为github page中项目的ip，可以通过在终端中输入ping https://yourname.github.io 找到，也可在Github help中找到。登陆namesilo，在右侧找到domain manager,进入后选择更改nameserver,处理过程还是挺长的，所以不用急着登陆你的域名 更改blog主题在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。为了描述方便，在以下说明中，将前者称为站点配置文件， 后者称为主题配置文件 选择主题进入官网选择适合的主题[hexo](https://hexo.io/themes/)，进入相应的Github地址，git clone命令把整个文件夹都下载下来，存放在Hexo/themes文件夹中。 更改配置文件一般而言，下载下来的主题文件中都有新手引导，注意readme就ok了。 部署项目代码在Hexo/_config.yml和themes里面的config文件中添加以下说明1234deploy: type: git repo: https://github.com/aier02/aier02.github.io.git branch: master注意修改repo的地址为你的github上面的地址(只要修改你的用户名)在Hexo目录下输入1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d即可将本地下的Hexo/public文件夹所有内容上传到github项目中(可能需要生成公私钥，请自行百度）hexo clean实质是删除Hexo/public，而hexo g则是根据配置和Hexo/source生成Hexo/public,新写的blog存放在Hexo/source/_posts即可，hexo d命令则是将Hexo/public上传到git服务器中,使用个人域名的同学还得在Github上面的yourname.github.io仓库根目录下新建一个CNAME文件，写入你的个人域名,不需要http和www,比如我的就是在第一行为：aier02.com 个人寄语blog关键在于内容，所以我基本很多操作都是为了方便，倘若遇到了什么问题可在下方评论提出(主要是看我是否也遇到了可以提供解决方案，没有踩过的坑我也不会=。=）,还有可以选择的theme很多，奉劝各位以实用为主，再好看的blog没有内容也是没价值的。","categories":[{"name":"blog","slug":"blog","permalink":"http://aier02.com/categories/blog/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://aier02.com/tags/Hexo/"},{"name":"Github page","slug":"Github-page","permalink":"http://aier02.com/tags/Github-page/"},{"name":"namesilo","slug":"namesilo","permalink":"http://aier02.com/tags/namesilo/"}]}]}